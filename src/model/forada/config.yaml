# log dir 
log_dir: /data/cuixinjie/FA/logs/new
#log_dir: /data/cuixinjie/DsClip_V2/log
lmdb: False
mode: train
dry_run: false
model_name: 'ds'
inter: 'none'
task_target: " "
save_avg: True
#queue_size: 2048
#random_k: 256
loss_rate: "10 * loss1 +  200 * loss_mse + 20* loss_intra + 10 *loss_inter"
vit_name: 'vit_tiny_patch16_224'
train_set: 'ori'
num_quires: 128
fusion_map: {1: 1, 2: 8, 3: 15}
clip_model_name: "ViT-L/14"
#clip_model_name: "ViT-B/16"

#clip_model_name: "data/cuixinjie/ViT-L-14.pt"

device: 'cuda:0'
mlp_dim: 256
mlp_out_dim: 128
head_num: 16  # for  clip_model_name: "ViT-L/14"
# dataset
all_dataset: [FaceForensics++, FF-F2F, FF-DF, FF-FS, FF-NT, FaceShifter, DeepFakeDetection, Celeb-DF-v1, Celeb-DF-v2, DFDCP, DFDC, DeeperForensics-1.0, UADFV]
train_dataset: [FaceForensics++]
#test_dataset: [FaceForensics++]
test_dataset: [FaceForensics++]

#test_dataset: [FaceForensics++]


#test_dataset: [FF-F2F]

#dataset_json_folder: '/media/ouc/新加卷/DS_CLIP_V2/dataset/dataset_json'
dataset_json_folder: '/data/cuixinjie/dataset/dataset_json'

compression: c23  # compression-level for videos
train_batchSize: 20   # training batch size
test_batchSize: 64   # test batch size
workers: 8   # number of data loading workers
frame_num: {'train': 32, 'test': 32}   # number of frames to use per video in training and testing
resolution: 256   # resolution of output image to network
with_mask: true   # whether to include mask information in the input
with_xray: true
with_patch_labels: true
with_landmark: false   # whether to include facial landmark information in the input
# label settings
label_dict:
  # DFD
  DFD_fake: 1
  DFD_real: 0
  # FF++ + FaceShifter(FF-real+FF-FH)
  FF-SH: 1
  FF-F2F: 1
  FF-DF: 1
  FF-FS: 1
  FF-NT: 1
  FF-FH: 1
  FF-real: 0
  # CelebDF
  CelebDFv1_real: 0
  CelebDFv1_fake: 1
  CelebDFv2_real: 0
  CelebDFv2_fake: 1
  # DFDCP
  DFDCP_Real: 0
  DFDCP_FakeA: 1
  DFDCP_FakeB: 1
  # DFDC
  DFDC_Fake: 1
  DFDC_Real: 0
  # DeeperForensics-1.0
  DF_fake: 1
  DF_real: 0
  # UADFV
  UADFV_Fake: 1
  UADFV_Real: 0



# data augmentation
use_data_augmentation: false  # Add this flag to enable/disable data augmentation
data_aug:
  flip_prob: 0.5
  rotate_prob: 0.5
  rotate_limit: [-10, 10]
  blur_prob: 0.5
  blur_limit: [3, 7]
  brightness_prob: 0.5
  brightness_limit: [-0.1, 0.1]
  contrast_limit: [-0.1, 0.1]
  quality_lower: 40
  quality_upper: 100

# mean and std for normalization
mean: [0.48145466, 0.4578275, 0.40821073]
std: [0.26862954, 0.26130258, 0.27577711]

# optimizer config
optimizer:
  # choose between 'adam' and 'sgd'
  type: adam
  adam:
    lr: 0.0002  # learning rate
    beta1: 0.9  # beta1 for Adam optimizer
    beta2: 0.999 # beta2 for Adam optimizer
    eps: 0.00000001  # epsilon for Adam optimizer
    weight_decay: 0.0005  # weight decay for regularization
    amsgrad: false
  sgd:
    lr: 0.0002  # learning rate
    momentum: 0.9  # momentum for SGD optimizer
    weight_decay: 0.0005  # weight decay for regularization

# training config
lr_scheduler: null   # learning rate scheduler
nEpochs: 60   # number of epochs to train for
start_epoch: 0    # manual epoch number (useful for restarts)
save_epoch: 2   # interval epochs for saving models
rec_iter: 100   # interval iterations for recording
#logdir: /media/ouc/新加卷/DS_CLIP_V2/log  # folder to output images and logs

manualSeed: 1020   # manual seed for random number generation
save_ckpt: true   # whether to save checkpoiccnt
save_feat: false

# metric
metric_scoring: auc   # metric for evaluation (auc, acc, eer, ap)

# cuda
ngpu: 1   # number of GPUs to use
cuda: true   # whether to use CUDA acceleration
cudnn: true   # whether to use CuDNN for convolution operations
